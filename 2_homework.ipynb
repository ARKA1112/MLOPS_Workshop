{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_parquet(\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-01.parquet\")\n",
    "\n",
    "val  = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-02.parquet')\n",
    "\n",
    "test = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2022-03.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:14:21</td>\n",
       "      <td>2022-01-01 00:15:33</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:20:55</td>\n",
       "      <td>2022-01-01 00:29:38</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>116</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:57:02</td>\n",
       "      <td>2022-01-01 01:13:14</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>140</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.70</td>\n",
       "      <td>14.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:07:42</td>\n",
       "      <td>2022-01-01 00:15:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.69</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:07:50</td>\n",
       "      <td>2022-01-01 00:28:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.3</td>\n",
       "      <td>31.26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2022-01-01 00:14:21   2022-01-01 00:15:33                  N   \n",
       "1         1  2022-01-01 00:20:55   2022-01-01 00:29:38                  N   \n",
       "2         1  2022-01-01 00:57:02   2022-01-01 01:13:14                  N   \n",
       "3         2  2022-01-01 00:07:42   2022-01-01 00:15:57                  N   \n",
       "4         2  2022-01-01 00:07:50   2022-01-01 00:28:52                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0         1.0            42            42              1.0           0.44   \n",
       "1         1.0           116            41              1.0           2.10   \n",
       "2         1.0            41           140              1.0           3.70   \n",
       "3         1.0           181           181              1.0           1.69   \n",
       "4         1.0            33           170              1.0           6.26   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount ehail_fee  \\\n",
       "0          3.5   0.50      0.5        0.00           0.0      None   \n",
       "1          9.5   0.50      0.5        0.00           0.0      None   \n",
       "2         14.5   3.25      0.5        4.60           0.0      None   \n",
       "3          8.0   0.50      0.5        0.00           0.0      None   \n",
       "4         22.0   0.50      0.5        5.21           0.0      None   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3          4.80           2.0        1.0   \n",
       "1                    0.3         10.80           2.0        1.0   \n",
       "2                    0.3         23.15           1.0        1.0   \n",
       "3                    0.3          9.30           2.0        1.0   \n",
       "4                    0.3         31.26           1.0        1.0   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                  0.00  \n",
       "1                  0.00  \n",
       "2                  2.75  \n",
       "3                  0.00  \n",
       "4                  2.75  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(df: pd.DataFrame):\n",
    "    #df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df['lpep_dropoff_datetime'] - df['lpep_pickup_datetime']\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(train_df, val_df, test_df):\n",
    "    df_train = read_dataframe(train_df)\n",
    "    df_val = read_dataframe(val_df)\n",
    "    df_test = read_dataframe(test_df)\n",
    "\n",
    "    target = 'tip_amount'\n",
    "\n",
    "    y_train = df_train[target].values\n",
    "    y_val= df_val[target].values\n",
    "    y_test = df_test[target].values\n",
    "\n",
    "    \"\"\"Init the dictvectorizer\"\"\" \n",
    "    dv = DictVectorizer()\n",
    "    X_train, dv = preprocess(df_train, dv, fit_dv=True)\n",
    "    X_val, _ = preprocess(df_val, dv, fit_dv=False)\n",
    "    X_test, _ = preprocess(df_test, dv, fit_dv=False)\n",
    "\n",
    "    return X_train,y_train,X_val,y_val,X_test,y_test,dv\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2791/1979658928.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n",
      "/tmp/ipykernel_2791/1979658928.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n",
      "/tmp/ipykernel_2791/1979658928.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n",
      "/tmp/ipykernel_2791/1979658928.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
      "/tmp/ipykernel_2791/1979658928.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
      "/tmp/ipykernel_2791/1979658928.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,X_val,y_val,X_test,y_test,dv = data_processing(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the dictvectorizer\n",
    "import pickle\n",
    "with open('2_homework/dv.pkl', 'wb') as file:\n",
    "    pickle.dump(dv, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "answer to the Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152K\t/home/ubuntu/notebooks/2_homework/dv.pkl\n"
     ]
    }
   ],
   "source": [
    "#To check the size of the file\n",
    "!du -h \"/home/ubuntu/notebooks/2_homework/dv.pkl\"\n",
    "\n",
    "#the answer is b-154kb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 Train a model with autolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(X_train,y_train,X_val,y_val,model):\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_pred,y_val)\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = RandomForestRegressor(max_depth=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/5', creation_time=1706856376705, experiment_id='5', last_update_time=1706856376705, lifecycle_stage='active', name='2_homework', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"2_homework\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/02 06:46:20 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.set_tag('Model','RandomForestRegressor')\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    #run the model\n",
    "    rmse = train_func(X_train,y_train,X_val,y_val,model)\n",
    "\n",
    "    #run the metric logging\n",
    "    mlflow.log_metric('RMSE',rmse)\n",
    "\n",
    "    #log the model artifact\n",
    "    mlflow.sklearn.log_model(model, artifact_path='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have been tasked to check the max_depth of the model\n",
    "# we will try it using mlflow client\n",
    "\n",
    "from mlflow.client import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=mlflow.get_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/5', creation_time=1706856376705, experiment_id='5', last_update_time=1706856376705, lifecycle_stage='active', name='2_homework', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/4', creation_time=1706710158792, experiment_id='4', last_update_time=1706710158792, lifecycle_stage='active', name='lightgbm prediction experiment', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/3', creation_time=1706708938289, experiment_id='3', last_update_time=1706708938289, lifecycle_stage='active', name='2_model_registry', tags={}>,\n",
       " <Experiment: artifact_location='/home/ubuntu/notebooks/mlruns/2', creation_time=1705592485729, experiment_id='2', last_update_time=1705592485729, lifecycle_stage='active', name='nyc_taxi_experiment', tags={}>,\n",
       " <Experiment: artifact_location='/home/ubuntu/notebooks/mlruns/1', creation_time=1705591891060, experiment_id='1', last_update_time=1705591891060, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1705588661834, experiment_id='0', last_update_time=1705588661834, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_experiments()\n",
    "#This lists all the experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This answers the 3rd question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the max_depth is 10\n"
     ]
    }
   ],
   "source": [
    "runs = client.search_runs(\n",
    "    experiment_ids=5\n",
    ")\n",
    "\n",
    "\n",
    "#since we know our experiment id is 5\n",
    "\n",
    "for run in runs:\n",
    "    print(f\"the max_depth is {run.data.params['max_depth']}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install optuna\n",
    "#first  lets define the objective function to try different values to tune using optuna \n",
    "# then define the objective function\n",
    "\n",
    "\n",
    "#import the necessary libs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "  #init the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    #define the hyperparams\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 10, 50, 1),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20, 1),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10, 1),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 4, 1),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    #model and features and targets have been initialized following previous experiments\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    return rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conduct the study and store the params in the study object\n",
    "sampler = optuna.samplers.TPESampler()\n",
    "study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study.optimize(objective,n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FrozenTrial(number=0, state=1, values=[2.4539999227851617], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 47, 535833), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 52, 195588), params={'n_estimators': 41, 'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 1}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=0, value=None),\n",
       " FrozenTrial(number=1, state=1, values=[2.4526464641463614], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 52, 196689), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 52, 987816), params={'n_estimators': 16, 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=1, value=None),\n",
       " FrozenTrial(number=2, state=1, values=[2.4669240128642773], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 52, 988867), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 53, 531683), params={'n_estimators': 19, 'max_depth': 7, 'min_samples_split': 8, 'min_samples_leaf': 1}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=2, value=None),\n",
       " FrozenTrial(number=3, state=1, values=[2.462916825536363], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 53, 532736), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 53, 948314), params={'n_estimators': 15, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 4}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=3, value=None),\n",
       " FrozenTrial(number=4, state=1, values=[2.464042365132163], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 53, 949971), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 55, 744877), params={'n_estimators': 31, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 1}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=4, value=None),\n",
       " FrozenTrial(number=5, state=1, values=[2.4569246116760715], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 55, 745946), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 57, 67099), params={'n_estimators': 36, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 2}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=5, value=None),\n",
       " FrozenTrial(number=6, state=1, values=[2.4605114528305077], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 57, 68629), datetime_complete=datetime.datetime(2024, 2, 2, 8, 43, 59, 650905), params={'n_estimators': 38, 'max_depth': 13, 'min_samples_split': 9, 'min_samples_leaf': 1}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=6, value=None),\n",
       " FrozenTrial(number=7, state=1, values=[2.446874709704634], datetime_start=datetime.datetime(2024, 2, 2, 8, 43, 59, 652072), datetime_complete=datetime.datetime(2024, 2, 2, 8, 44, 4, 243912), params={'n_estimators': 37, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 2}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=7, value=None),\n",
       " FrozenTrial(number=8, state=1, values=[2.4620993479009456], datetime_start=datetime.datetime(2024, 2, 2, 8, 44, 4, 245278), datetime_complete=datetime.datetime(2024, 2, 2, 8, 44, 5, 498488), params={'n_estimators': 50, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 1}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=8, value=None),\n",
       " FrozenTrial(number=9, state=1, values=[2.467546050115874], datetime_start=datetime.datetime(2024, 2, 2, 8, 44, 5, 499648), datetime_complete=datetime.datetime(2024, 2, 2, 8, 44, 6, 306362), params={'n_estimators': 38, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 2}, user_attrs={}, system_attrs={}, intermediate_values={}, distributions={'n_estimators': IntDistribution(high=50, log=False, low=10, step=1), 'max_depth': IntDistribution(high=20, log=False, low=1, step=1), 'min_samples_split': IntDistribution(high=10, log=False, low=2, step=1), 'min_samples_leaf': IntDistribution(high=4, log=False, low=1, step=1)}, trial_id=9, value=None)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials=study.get_trials() #get all the trials conducted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials[0].number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now for each trial conduct an exp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before that we will need to delete the existing deleted experiment permanently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Cannot set a deleted experiment 'random-forest-hyperopt' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#create an experiment\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom-forest-hyperopt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m trials:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/mlflow/tracking/fluent.py:155\u001b[0m, in \u001b[0;36mset_experiment\u001b[0;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    150\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment with ID \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    151\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mRESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    152\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mlifecycle_stage \u001b[38;5;241m!=\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mACTIVE:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    156\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a deleted experiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as the active experiment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can restore the experiment, or permanently delete the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment to create a new one.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m experiment\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    160\u001b[0m         ),\n\u001b[1;32m    161\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _active_experiment_id\n\u001b[1;32m    165\u001b[0m _active_experiment_id \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39mexperiment_id\n",
      "\u001b[0;31mMlflowException\u001b[0m: Cannot set a deleted experiment 'random-forest-hyperopt' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one."
     ]
    }
   ],
   "source": [
    "\n",
    "#create an experiment\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "for trial in trials:\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"Trial No\",trial.number)\n",
    "\n",
    "        #logs\n",
    "        mlflow.log_params(trial.params)\n",
    "\n",
    "        model = RandomForestRegressor(**trial.params)\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val,y_pred, squared=False)\n",
    "        #log the artifact\n",
    "        mlflow.sklearn.log_model(model,artifact_path=\"models\")\n",
    "\n",
    "        #log the metrics\n",
    "        mlflow.log_metric('rmse',rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        #get the best model\n",
    "best_model = RandomForestRegressor(**study.best_params)\n",
    "\n",
    "        #log the best model\n",
    "mlflow.sklearn.log_model(best_model,artifact_path=\"models\")\n",
    "\n",
    "        #eval the model\n",
    "best_model.fit(X_train,y_train)\n",
    "        y_pred = best_model.predict(X_val)\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "        mlflow.log_metric('rmse',rmse)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstudy\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "client = MlflowClient(tracking_uri=\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='mlflow-artifacts:/6', creation_time=1706861480031, experiment_id='6', last_update_time=1706861480031, lifecycle_stage='active', name='random-forest-hyperopt', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/5', creation_time=1706856376705, experiment_id='5', last_update_time=1706856376705, lifecycle_stage='active', name='2_homework', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/4', creation_time=1706710158792, experiment_id='4', last_update_time=1706710158792, lifecycle_stage='active', name='lightgbm prediction experiment', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/3', creation_time=1706708938289, experiment_id='3', last_update_time=1706708938289, lifecycle_stage='active', name='2_model_registry', tags={}>,\n",
       " <Experiment: artifact_location='/home/ubuntu/notebooks/mlruns/2', creation_time=1705592485729, experiment_id='2', last_update_time=1705592485729, lifecycle_stage='active', name='nyc_taxi_experiment', tags={}>,\n",
       " <Experiment: artifact_location='/home/ubuntu/notebooks/mlruns/1', creation_time=1705591891060, experiment_id='1', last_update_time=1705591891060, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>,\n",
       " <Experiment: artifact_location='mlflow-artifacts:/0', creation_time=1705588661834, experiment_id='0', last_update_time=1705588661834, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best rmse score is {'rmse': 2.4481454701058243}\n"
     ]
    }
   ],
   "source": [
    "runs = client.search_runs(experiment_ids=6,max_results=1)\n",
    "for run in runs:\n",
    "    print(f\"The best rmse score is {run.data.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/02 08:29:45 INFO mlflow.tracking.fluent: Experiment with name 'random_forest_best_model' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/7', creation_time=1706862585292, experiment_id='7', last_update_time=1706862585292, lifecycle_stage='active', name='random_forest_best_model', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##REGISTER THE BEST MODEL\n",
    "\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.entities import ViewType\n",
    "\n",
    "\n",
    "\n",
    "mlflow.set_experiment('random_forest_best_model')\n",
    "#mlflow.set_tracking_uri(uri='http://localhost:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
